{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import forge\n",
    "from data import warehouse\n",
    "from puzzle.puzzlepedia import prod_config\n",
    "prod_config.init()\n",
    "\n",
    "trie = warehouse.get('/words/unigram/trie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 5), (4, 6), (3, 7), (2, 8)]\n"
     ]
    }
   ],
   "source": [
    "word = 'CHEAPSKATE'\n",
    "targets = []\n",
    "for x in reversed(range(2, round(len(word) / 2) + 1)):\n",
    "  targets.append((x, len(word) - x))\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.seek_sets import chain_seek_set\n",
    "\n",
    "def process(word, interesting=set(), required=None, length=None):\n",
    "  word = word.lower()\n",
    "  seek_set = chain_seek_set.ChainSeekSet(list(word), len(word))\n",
    "  if length:\n",
    "    lengths = [(length, len(word) - length)]\n",
    "  else:\n",
    "    lengths = targets(word)\n",
    "  for target in lengths:\n",
    "    if required and len(required) not in target:\n",
    "      continue\n",
    "    for result in walk(seek_set, [], target):\n",
    "      parts = result.split()\n",
    "      if required and required not in parts:\n",
    "        continue\n",
    "      a, b = parts\n",
    "      if a in interesting or b in interesting:\n",
    "        flag = '*'\n",
    "      else:\n",
    "        flag = ' '\n",
    "      print('%s %s (%s)' % (flag, result, word))\n",
    "\n",
    "def targets(word):\n",
    "  targets = []\n",
    "  for x in reversed(range(2, round(len(word) / 2) + 1)):\n",
    "    targets.append((x, len(word) - x))\n",
    "  return targets\n",
    "\n",
    "def walk(seek_set, acc, targets, pos=0):\n",
    "  if pos >= len(targets):\n",
    "    yield ' '.join(acc)\n",
    "    return\n",
    "  target = targets[pos]\n",
    "  seek_set.set_length(target)\n",
    "  for result, weight in trie.walk(seek_set, exact_match=True):\n",
    "    if weight < 5e4:\n",
    "      break\n",
    "    acc.append(result)\n",
    "    yield from walk(seek_set[result:], acc, targets, pos+1)\n",
    "    acc.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  indian tarlton (antinrtlanoid)\n",
      "  inland tration (antinrtlanoid)\n",
      "  intron lindata (antinrtlanoid)\n",
      "  linton radiant (antinrtlanoid)\n",
      "  tintin arnaldo (antinrtlanoid)\n",
      "  andnot ritalin (antinrtlanoid)\n",
      "  tannin dilator (antinrtlanoid)\n",
      "  tandon ritalin (antinrtlanoid)\n",
      "  titian norland (antinrtlanoid)\n",
      "  dannii tarlton (antinrtlanoid)\n",
      "  darton lintian (antinrtlanoid)\n",
      "  tinton irlanda (antinrtlanoid)\n",
      "  tinton darlina (antinrtlanoid)\n",
      "  indain tarlton (antinrtlanoid)\n",
      "  danton ritalin (antinrtlanoid)\n",
      "  nordin atitlan (antinrtlanoid)\n",
      "  dannil tration (antinrtlanoid)\n",
      "  lannan diritto (antinrtlanoid)\n",
      "  niland tration (antinrtlanoid)\n",
      "  raton dilantin (antinrtlanoid)\n",
      "  trond nainital (antinrtlanoid)\n",
      "  torna dilantin (antinrtlanoid)\n"
     ]
    }
   ],
   "source": [
    "process('ANTINRTLANOID', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  squire fence (frequencies)\n",
      "  risque fence (frequencies)\n",
      "  cinque reefs (frequencies)\n",
      "  cinque frees (frequencies)\n",
      "  squier fence (frequencies)\n",
      "  quince reefs (frequencies)\n",
      "  quince frees (frequencies)\n",
      "  quence fires (frequencies)\n",
      "  quence fries (frequencies)\n",
      "  quence serif (frequencies)\n",
      "  quence frise (frequencies)\n",
      "  quires fence (frequencies)\n",
      "  fence squire (frequencies)\n",
      "  fence risque (frequencies)\n",
      "  fence squier (frequencies)\n",
      "  fence quires (frequencies)\n",
      "  fires quence (frequencies)\n",
      "  fries quence (frequencies)\n",
      "  serif quence (frequencies)\n",
      "  reefs cinque (frequencies)\n",
      "  reefs quince (frequencies)\n",
      "  frees cinque (frequencies)\n",
      "  frees quince (frequencies)\n",
      "  frise quence (frequencies)\n",
      "  fire quences (frequencies)\n",
      "  if sequencer (frequencies)\n"
     ]
    }
   ],
   "source": [
    "process('FREQUENCIES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78f382c4e52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ANTINRELANOID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "process('ANTINRELANOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "long windy\n",
      "down lying\n",
      "(3, 6)\n",
      "(2, 7)\n",
      "in goldwyn\n"
     ]
    }
   ],
   "source": [
    "process('LYINGDOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(3, 4)\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "process('NONJURY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "pack power\n",
      "(3, 6)\n",
      "pop wacker\n",
      "cow keppra\n",
      "(2, 7)\n",
      "we propack\n"
     ]
    }
   ],
   "source": [
    "process('POWERPACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "page plain\n",
      "page palin\n",
      "plan paige\n",
      "pain plage\n",
      "gain apple\n",
      "gain appel\n",
      "gain papel\n",
      "pile pagan\n",
      "(3, 6)\n",
      "age lappin\n",
      "leg appian\n",
      "leg papain\n",
      "gap alpine\n",
      "gap nepali\n",
      "gap plaine\n",
      "gap pineal\n",
      "gap pelian\n",
      "gap lapine\n",
      "pen paglia\n",
      "lip pangea\n",
      "pig alpena\n",
      "lap pagine\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "process('APPEALING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "more nagin\n",
      "name groin\n",
      "name ringo\n",
      "game ronin\n",
      "main negro\n",
      "main norge\n",
      "main regno\n",
      "near mingo\n",
      "mean groin\n",
      "mean ringo\n",
      "ring eamon\n",
      "iron megan\n",
      "iron gmane\n",
      "iron amgen\n",
      "iron mange\n",
      "mine organ\n",
      "mine argon\n",
      "mine goran\n",
      "mine groan\n",
      "mine orang\n",
      "mine rogan\n",
      "nine margo\n",
      "rain gnome\n",
      "earn mingo\n",
      "norm angie\n",
      "grin eamon\n",
      "(3, 6)\n",
      "one margin\n",
      "one garmin\n",
      "one ingram\n",
      "one arming\n",
      "one ingmar\n",
      "man region\n",
      "man ignore\n",
      "man origen\n",
      "man orgien\n",
      "age mornin\n",
      "ago renmin\n",
      "ago minner\n",
      "nor enigma\n",
      "nor imagen\n",
      "nor ingame\n",
      "aim negron\n",
      "arm onegin\n",
      "era mignon\n",
      "ear mignon\n",
      "(2, 7)\n",
      "in marengo\n",
      "in morgane\n",
      "in germano\n",
      "in garnome\n",
      "on germain\n",
      "on reaming\n",
      "on ingemar\n",
      "or meaning\n",
      "no germain\n",
      "no reaming\n",
      "no ingemar\n",
      "re moaning\n",
      "re maginon\n",
      "go riemann\n",
      "go reimann\n",
      "go amerinn\n",
      "mr gennaio\n"
     ]
    }
   ],
   "source": [
    "process('ENAMORING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "area glebe\n",
      "able agree\n",
      "able eager\n",
      "able agere\n",
      "gear beale\n",
      "gear albee\n",
      "bear eagle\n",
      "beer algae\n",
      "bare eagle\n",
      "rage beale\n",
      "rage albee\n",
      "(3, 6)\n",
      "era beagle\n",
      "ear beagle\n",
      "bee galera\n",
      "beg aleera\n",
      "(2, 7)\n",
      "be realage\n"
     ]
    }
   ],
   "source": [
    "process('AGREEABLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cfc89d6c2449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compared'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "process('compared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from data import warehouse\n",
    "word_api = warehouse.get('/api/words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extras = {'shy', 'red', 'gel', 'lest', 'ed'}\n",
    "interesting = extras.union(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def syns(word, target_len):\n",
    "  word = word.lower()\n",
    "  process(word, interesting)\n",
    "  for w in word_api.synonyms(word):\n",
    "    if len(w) == target_len:\n",
    "      process(w, interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  need didst (distended)\n",
      "* seed didnt (distended)\n",
      "  tend sided (distended)\n",
      "  wide end (widened)\n",
      "  end wide (widened)\n",
      "  we dined (widened)\n",
      "  able dot (bloated)\n",
      "  load bet (bloated)\n",
      "  beat old (bloated)\n",
      "  bold eat (bloated)\n",
      "  bold tea (bloated)\n",
      "  old beat (bloated)\n",
      "  eat bold (bloated)\n",
      "  tea bold (bloated)\n",
      "  dot able (bloated)\n",
      "  bet load (bloated)\n",
      "  to blade (bloated)\n",
      "  to abdel (bloated)\n",
      "  at doble (bloated)\n",
      "  do table (bloated)\n",
      "  we dells (swelled)\n",
      "  seem cut (tumesce)\n",
      "  stem cue (tumesce)\n",
      "  cut seem (tumesce)\n",
      "  cue stem (tumesce)\n"
     ]
    }
   ],
   "source": [
    "syns('DISTENDED', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accessoryfruit\n",
      "achene\n",
      "ackee\n",
      "acorn\n",
      "aggregatefruit\n",
      "anchovypear\n",
      "apple\n",
      "apricot\n",
      "avocado\n",
      "banana\n",
      "barbadosgooseberry\n",
      "berry\n",
      "breadfruit\n",
      "buckthornberry\n",
      "buffalonut\n",
      "canistel\n",
      "carambola\n",
      "carissaplum\n",
      "ceriman\n",
      "cherry\n",
      "chokecherry\n",
      "citrus\n",
      "cling\n",
      "cocoaplum\n",
      "cubeb\n",
      "custardapple\n",
      "date\n",
      "driedfruit\n",
      "drupe\n",
      "durian\n",
      "ediblefruit\n",
      "elderberry\n",
      "feijoa\n",
      "fig\n",
      "freestone\n",
      "fruitlet\n",
      "garambulla\n",
      "genip\n",
      "genipap\n",
      "gourd\n",
      "grape\n",
      "guava\n",
      "hagberry\n",
      "hip\n",
      "hogplum\n",
      "jaboticaba\n",
      "jackfruit\n",
      "jujube\n",
      "juniperberry\n",
      "kaiapple\n",
      "ketembilla\n",
      "kiwi\n",
      "lanseh\n",
      "litchi\n",
      "longanberry\n",
      "loquat\n",
      "mamey\n",
      "mango\n",
      "mangosteen\n",
      "marang\n",
      "marasca\n",
      "mayapple\n",
      "medlar\n",
      "melon\n",
      "mombin\n",
      "nectarine\n",
      "olive\n",
      "papaw\n",
      "papaya\n",
      "passionfruit\n",
      "peach\n",
      "pear\n",
      "pineapple\n",
      "pitahaya\n",
      "plum\n",
      "plumcot\n",
      "pod\n",
      "pome\n",
      "pomegranate\n",
      "prairiegourd\n",
      "pricklypear\n",
      "pulasan\n",
      "pyxidium\n",
      "quandong\n",
      "quince\n",
      "rambutan\n",
      "roseapple\n",
      "rowanberry\n",
      "sapodilla\n",
      "sapote\n",
      "schizocarp\n",
      "seed\n",
      "sorb\n",
      "sourgourd\n",
      "tamarind\n",
      "tangelo\n",
      "wildcherry\n",
      "windfall\n"
     ]
    }
   ],
   "source": [
    "def clean(s):\n",
    "  # Convert \"dried_fruit.n.01\" to \"driedfruit\".\n",
    "  return s.name().split('.')[0].replace('_', '')\n",
    "\n",
    "def collect(acc, lemma):\n",
    "  s = wordnet.synset(lemma)\n",
    "  for f in s.hyponyms():\n",
    "    acc.add(clean(f))\n",
    "  \n",
    "fruits = set()\n",
    "collect(fruits, 'edible_fruit.n.01')\n",
    "collect(fruits, 'fruit.n.01')\n",
    "fruits.remove('ear')\n",
    "for fruit in sorted(fruits):\n",
    "  print(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import warehouse\n",
    "anagram_index = warehouse.get('/words/unigram/anagram_index')\n",
    "\n",
    "def scramble(bases, extra):\n",
    "  for base in bases:\n",
    "    search = base + extra\n",
    "    if search not in anagram_index:\n",
    "      continue\n",
    "    for result in anagram_index[base + extra]:\n",
    "      print(result, '=', base, '+', extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longacre = acorn + gel\n",
      "solberg = sorb + gel\n"
     ]
    }
   ],
   "source": [
    "scramble(fruits, 'gel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shy\n",
      "gel\n",
      "longacre = acorn + gel\n",
      "solberg = sorb + gel\n",
      "lest\n",
      "loveliest = olive + lest\n",
      "lobsters = sorb + lest\n",
      "bolsters = sorb + lest\n",
      "leapster = pear + lest\n",
      "prelates = pear + lest\n"
     ]
    }
   ],
   "source": [
    "candidates = \"\"\"\n",
    "shy gel lest\n",
    "\"\"\".split()\n",
    "for w in candidates:\n",
    "  print(w)\n",
    "  scramble(fruits, w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = \"\"\"\n",
    "entailing faltering filtering flagstone flowering forgetful galleries gargoyles gauntlets genealogy generally geniality genitalia gentleman gentlemen genuinely geologist ghastlier glaciated glassware gleanings gleefully glistened glorified glorifies glowering glutamate godliness graticule greyscale grovelled guardedly guerrilla guessable guideline guillemot heralding hexagonal ignorable illegally illegible impelling indulgent inelegant integrals irregular jestingly knowledge labelling lamenting languages largeness laughable leavening lecturing leeringly legalised legendary legionary legislate legstraps lengthier lessening lethargic lettering levelling licensing ligatured ligatures lightened lightness limelight lingering listening littering loitering longevity longitude loosening lumbering mellowing modelling molesting monologue neglected negligent neologism overlying panelling parleying pedalling pigtailed ploughers ploughmen privilege prologise prologize prologues prolonged ravelling realising realizing rebelling recalling reclining recoiling rectangle recycling refilling refluxing regretful regularly regulated regulates regulator releasing relegated relegates relieving religions religious relinking reloading repelling replacing replaying replugged resolving resulting retelling revealing revolting revolving rigmarole sacrilege salesgirl seedlings seemingly selecting shielding sidelight sightless signalled silencing singleton slaughter slavering slightest soldering spellings spillages squealing strangely strangled strangler strangles struggled struggles sugillate swellings tailgates telegrams telegraph trembling triangles trilogies unaligned underling unfeeling unplugged unsealing unveiling upwelling vegetable vestigial vigilance villagers welcoming wellbeing weltering wrestling yellowing\n",
    "\"\"\".split()\n",
    "for c in candidates:\n",
    "  process(c, interesting, required='gel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import forge\n",
    "from puzzle.puzzlepedia import puzzlepedia\n",
    "\n",
    "puzzle = puzzlepedia.parse(\"\"\"\n",
    "mppgao\n",
    "rn\n",
    "ldp\n",
    "abcdefghijklmnopqrstuvwxyz\n",
    "i\n",
    "mppgao\n",
    "eem\n",
    "arerpl\n",
    "mppgao\n",
    "nuaapi\n",
    "eem\n",
    "gncplv\n",
    "abcdefghijklmnopqrstuvwxyz\n",
    "rg\n",
    "\"\"\", hint='acrostic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  same hiper (herpameis)\n",
      "  rape imesh (herpameis)\n",
      "  hear mepis (herpameis)\n",
      "  seem phair (herpameis)\n",
      "  peer amish (herpameis)\n",
      "  peer misha (herpameis)\n",
      "  mere aphis (herpameis)\n",
      "  his ampere (herpameis)\n",
      "  she premia (herpameis)\n",
      "  she mperia (herpameis)\n",
      "  map heiser (herpameis)\n",
      "  him pearse (herpameis)\n",
      "  him speare (herpameis)\n",
      "  him espera (herpameis)\n",
      "  him sapere (herpameis)\n",
      "  aim sphere (herpameis)\n",
      "  aim herpes (herpameis)\n",
      "  hip sameer (herpameis)\n",
      "  hip meares (herpameis)\n",
      "  hip mersea (herpameis)\n",
      "  pie ramesh (herpameis)\n",
      "  pie shmera (herpameis)\n",
      "  pie masher (herpameis)\n",
      "  pie rhames (herpameis)\n",
      "  ash empire (herpameis)\n",
      "  he impresa (herpameis)\n",
      "  me sharpie (herpameis)\n",
      "  me saphire (herpameis)\n",
      "  hi empresa (herpameis)\n",
      "  hi amperes (herpameis)\n",
      "  ie hampers (herpameis)\n",
      "  ha premise (herpameis)\n",
      "  ha empires (herpameis)\n",
      "  ha siempre (herpameis)\n",
      "  ha imprese (herpameis)\n",
      "  ah premise (herpameis)\n",
      "  ah empires (herpameis)\n",
      "  ah siempre (herpameis)\n",
      "  ah imprese (herpameis)\n"
     ]
    }
   ],
   "source": [
    "process('herpameis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\tS\tI\tU\tB\tL\tE\tR\tA\tM\tI\tS\tH\tT\tE\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join('O S I U B L E R A M I S H T E'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
