{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from forge import *\n",
    "from puzzle.puzzlepedia import prod_config\n",
    "\n",
    "prod_config.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import importlib\n",
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from ipywidgets import widgets\n",
    "from os import path\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from data import data\n",
    "from util import perf\n",
    "from util.geometry import np2d\n",
    "from data.image import coloring, component, component_database, image, utils\n",
    "from puzzle.problems.image import image_problem\n",
    "from puzzle.steps.image import decompose\n",
    "\n",
    "importlib.reload(image)\n",
    "importlib.reload(np2d)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(coloring)\n",
    "\n",
    "\n",
    "_FILE_PATTERN = '*.png'\n",
    "_MAX = 255\n",
    "_THRESHOLD = 5\n",
    "_FOCUS = {\n",
    "}\n",
    "\n",
    "  \n",
    "def image_path(name: str, subdir: str = 'original') -> str:\n",
    "  return path.join(data.project_path('data/grid'), subdir, name)\n",
    "\n",
    "\n",
    "def get_img(name, subdir: str = 'original'):\n",
    "  # download the image, convert it to a NumPy array, and then read\n",
    "  # it into OpenCV format\n",
    "  return cv2.imread(image_path(name, subdir=subdir), flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "def get_image(name):\n",
    "  return image.Image(get_img(name))\n",
    "\n",
    "\n",
    "def show(label, img=None):\n",
    "  if img is None:\n",
    "    img = label\n",
    "  else:\n",
    "    print(label)\n",
    "\n",
    "  height, width = img.shape[:2]\n",
    "  f = io.BytesIO()\n",
    "  Image.fromarray(np.array(img, dtype=np.uint8)).save(f, 'png')\n",
    "  # This method keeps data out of notebook source.\n",
    "  display(widgets.Image(\n",
    "      value=f.getvalue(),\n",
    "      width=width,\n",
    "      height=height,\n",
    "  ))\n",
    "\n",
    "\n",
    "def show_components(g):\n",
    "  db = component_database.ComponentDatabase()\n",
    "\n",
    "  shown = set()\n",
    "  for c in g.components:\n",
    "    identified = db.identify(c)\n",
    "    symbol = identified.labels.get('symbol')\n",
    "    if symbol is None:\n",
    "      pass\n",
    "    elif symbol in shown:\n",
    "      continue\n",
    "    shown.add(symbol)\n",
    "    show(c.image)\n",
    "\n",
    "\n",
    "def imgs(subdir: str = 'original') -> Iterable[np.ndarray]:\n",
    "  for filename in sorted(glob.glob(image_path(_FILE_PATTERN, subdir))):\n",
    "    name = path.basename(filename)\n",
    "    if _FOCUS and name not in _FOCUS:\n",
    "      continue\n",
    "    yield (\n",
    "      name,\n",
    "      cv2.imread(filename, flags=cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "\n",
    "def images() -> Iterable[image.Image]:\n",
    "  for name, img in imgs():\n",
    "    if _FOCUS and name not in _FOCUS:\n",
    "      continue\n",
    "    yield name, image.Image(img)\n",
    "\n",
    "\n",
    "_PADDING = 8\n",
    "\n",
    "\n",
    "def study(*segments, padding=_PADDING):\n",
    "  \"\"\"Studies line segments.\"\"\"\n",
    "  segments = [np.array(s) for s in segments]\n",
    "  min_x = min(s[:, 0].min() for s in segments)\n",
    "  min_y = min(s[:, 1].min() for s in segments)\n",
    "  move_to_zero = np.array([min_x, min_y])\n",
    "  for s in segments:\n",
    "    print(repr(s))\n",
    "    s -= move_to_zero - padding\n",
    "  max_x = int(max(s[:, 0].max() for s in segments) + padding)\n",
    "  max_y = int(max(s[:, 1].max() for s in segments) + padding)\n",
    "  image = np.zeros((max_y + 1, max_x + 1, 3), dtype=np.uint8)\n",
    "  colors = coloring.colors(len(segments))\n",
    "  for s, color in zip(segments, colors):\n",
    "    cv2.line(image, tuple(map(int, s[0])), tuple(map(int, s[1])), color.tolist(), 1)\n",
    "  image = cv2.resize(image, None, fx=2, fy=2)\n",
    "  show(image)\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on (1438x1361)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151f0f4dac644d42b45a16d13d68ec14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\x9e\\x00\\x00\\x05Q\\x08\\x00\\x00\\x00\\x00%?\\xc3#\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf9ae6f87604b81bfa1f5b7e4acb41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\x9e\\x00\\x00\\x05Q\\x08\\x02\\x00\\x00\\x00\\x8f6\\x0b\\xa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.image import contours_classifier, coloring, component, component_database, divide_distances_evenly, image, lines_classifier, utils\n",
    "from puzzle.steps.image import identify_regions\n",
    "\n",
    "importlib.reload(identify_regions)\n",
    "importlib.reload(lines_classifier)\n",
    "importlib.reload(contours_classifier)\n",
    "\n",
    "identify_regions.show = show\n",
    "contours_classifier.show = show\n",
    "\n",
    "_FOCUS = {\n",
    "# 'arrow.png',\n",
    "# 'askew.png',\n",
    "# 'cages.png',\n",
    "# 'castlewall.png',\n",
    "# 'consecutive.png',\n",
    "# 'crossword.png',\n",
    "# 'fillomino.png',\n",
    "# 'kakuro.png',\n",
    "# 'kenken.png',\n",
    "'nonogram.png',\n",
    "# 'nurimaze.png',\n",
    "# 'masyu.png',\n",
    "# 'multi.png',\n",
    "# 'pentopia.png',\n",
    "# 'skyscraper.png',\n",
    "# 'pathfinder.png',\n",
    "# 'thermo.png',\n",
    "# 'rowsgarden.png',\n",
    "# 'slitherlink.png',\n",
    "# 'spiral.png',\n",
    "# 'strimko.png',\n",
    "# 'wordsearch.png',\n",
    "# 'wordsearch_with_bank.png',  # TODO: Restore this image.\n",
    "}\n",
    "for n, i in imgs():\n",
    "  p = image_problem.ImageProblem(n, i)\n",
    "\n",
    "  p._identify_regions._debug()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrow.png (0.3274%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546bdb2b8834412ab0ce25ef8c77656a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x9e\\x00\\x00\\x01u\\x08\\x00\\x00\\x00\\x00\\xfd\\x94\\xd3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askew.png (0.1976%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a58e4051e12438e98219f7c3c9cbe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xa4\\x00\\x00\\x01l\\x08\\x00\\x00\\x00\\x00\\xa6\\x9c\\x92…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cages.png (0.7996%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c345d9ca6334ec3bd7f2604a4927e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\xd3\\x00\\x00\\x02\\xd3\\x08\\x00\\x00\\x00\\x00\\xf1\\x9f\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castlewall.png (0.3550%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f420ffc70924254a3e79696ac017fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xb5\\x00\\x00\\x01\\x93\\x08\\x00\\x00\\x00\\x00\\x8a4\\xd3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consecutive.png (0.4191%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c46ef05e7a7427a90b9656dab342b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x9b\\x00\\x00\\x01u\\x08\\x00\\x00\\x00\\x00\\x1b\\xbd\\x18…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossword.png (0.5255%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba8c4f5769843598499187e4ecc6268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\"\\x00\\x00\\x02\"\\x08\\x00\\x00\\x00\\x00\\xd0\\xdf\\xfc\\xf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fillomino.png (0.2210%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba39300250fe4802a8a1b27ad318c23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xe5\\x00\\x00\\x01\\xe5\\x08\\x00\\x00\\x00\\x00\\xee[\\xbb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kakuro.png (0.6739%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8474238c19f492899387c2812da1d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x8d\\x00\\x00\\x01\\xaf\\x08\\x00\\x00\\x00\\x00\\x82\\xa8\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kenken.png (0.6377%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a12fc5bc5a44169e62e26c77f59bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xf4\\x00\\x00\\x01\\xf4\\x08\\x00\\x00\\x00\\x00\\xee\\xbd\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masyu.png (0.1685%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a17fe4692b84f669fc0fd17fe886204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xd5\\x00\\x00\\x01\\xb5\\x08\\x00\\x00\\x00\\x00\\x8a&1q\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi.png (0.3761%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988fc5817a2e4eb9ac9ebc17bf046ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xe7\\x00\\x00\\x01\\xe7\\x08\\x00\\x00\\x00\\x00\\xa7f\\xca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonogram.png (0.7420%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42085e3dff44f85bb39d0fe73575192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\x9e\\x00\\x00\\x05Q\\x08\\x00\\x00\\x00\\x00%?\\xc3#\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nurimaze.png (0.9402%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8de0f455b5c422896c6e58fee26c260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x069\\x00\\x00\\x069\\x08\\x00\\x00\\x00\\x00\"\\x16# \\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathfinder.png (0.3624%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06a2f399fa64938aa255185649b8b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\xc6\\x00\\x00\\x05\\x1f\\x08\\x00\\x00\\x00\\x00\\xba\\xaen…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pentopia.png (0.2286%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82dce90bfc74a8a93e0935b89dc331f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xfd\\x00\\x00\\x03\\x18\\x08\\x00\\x00\\x00\\x00\\xe4\\xb1a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowsgarden.png (0.6938%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b72cc00061d4a269920c81270be7ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x03\\xdd\\x00\\x00\\x03R\\x08\\x00\\x00\\x00\\x00]C\\xf2W\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skyscraper.png (0.3392%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ec2fbe7a9d4dae96950836597420f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x19\\x00\\x00\\x01\\x1f\\x08\\x00\\x00\\x00\\x00P\"\\xed\\xd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slitherlink.png (0.1345%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73762ac0b5f41f3af79df4b324358ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01w\\x00\\x00\\x01S\\x08\\x00\\x00\\x00\\x00\\xe7\\x96\\x13\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strimko.png (0.2692%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3219e583f28a4f23922c69d24a808931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xcd\\x00\\x00\\x00\\xcd\\x08\\x00\\x00\\x00\\x00>\\xd7\\xab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thermo.png (0.7311%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8197685b936542c9b583dc6268cdebe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\'\\x00\\x00\\x02c\\x08\\x00\\x00\\x00\\x00\\xf2\\xf2\\xee{\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordsearch.png (0.6270%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a4b304026a4ddc8574a32d58b6e451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02[\\x00\\x00\\x02[\\x08\\x00\\x00\\x00\\x00\\xf6\\xae\\x0e\\xa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.image import lines_classifier, coloring, component, component_database, divide_distances_evenly, image, utils\n",
    "from util.geometry import np2d\n",
    "from puzzle.constraints.image import decompose_constraints\n",
    "from puzzle.constraints.image import lines_classifier_constraints\n",
    "from util import perf\n",
    "\n",
    "importlib.reload(coloring)\n",
    "importlib.reload(divide_distances_evenly)\n",
    "importlib.reload(np2d)\n",
    "#importlib.reload(perf)\n",
    "importlib.reload(lines_classifier)\n",
    "importlib.reload(lines_classifier_constraints)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(decompose_constraints)\n",
    "importlib.reload(decompose)\n",
    "importlib.reload(image)\n",
    "importlib.reload(image_problem)\n",
    "\n",
    "#image.show = show\n",
    "decompose.show = show\n",
    "lines_classifier.show = show\n",
    "lines_classifier.plt = plt\n",
    "\n",
    "\n",
    "_FOCUS = {\n",
    "# 'arrow.png',\n",
    "# 'askew.png',\n",
    "# 'cages.png',\n",
    "# 'castlewall.png',\n",
    "# 'consecutive.png',\n",
    "# 'crossword.png',\n",
    "# 'fillomino.png',\n",
    "# 'kakuro.png',\n",
    "# 'kenken.png',\n",
    "# 'nonogram.png',\n",
    "# 'nurimaze.png',\n",
    "# 'masyu.png',\n",
    "# 'multi.png',\n",
    "# 'pentopia.png',\n",
    "# 'skyscraper.png',\n",
    "# 'pathfinder.png',\n",
    "# 'thermo.png',\n",
    "# 'rowsgarden.png',\n",
    "# 'slitherlink.png',\n",
    "# 'spiral.png',\n",
    "# 'strimko.png',\n",
    "# 'wordsearch.png',\n",
    "# 'wordsearch_with_bank.png',  # TODO: Restore this image.\n",
    "}\n",
    "# Boundary shy: crossword.png, fillomino.png, kakuro.png, masyu.png\n",
    "# ???: wordsearch.png, kakuro.png, fillomino.png, consecutive.png, castlewall.png\n",
    "# Skips points: fillomino.png\n",
    "# Slow: wordsearch.png\n",
    "# Imprecise: askew.png, kakuro.png, multi.png, rowsgarden.png, wordsearch.png\n",
    "# Angle clamping: arrow.png, kakuro.png, nonogram.png, rowsgarden.png\n",
    "# Very slow: wordsearch_with_bank.png.\n",
    "# Broken with \"optimal\" fixes: kakuro.png, kenken.png\n",
    "\n",
    "DEBUG = len(_FOCUS) > 0\n",
    "lines_classifier.DEBUG = DEBUG\n",
    "divide_distances_evenly.DEBUG = DEBUG\n",
    "\n",
    "\n",
    "for n, i in imgs():\n",
    "  p = image_problem.ImageProblem(n, i)\n",
    "  height, width = p._prepare_image.get_result().shape[:2]\n",
    "  threshold = int(min(width, height) // 2)\n",
    "  dst = cv2.cvtColor(p._prepare_image.get_debug_data(), cv2.COLOR_GRAY2BGR)\n",
    "  prepared_result = p._prepare_image.get_result()\n",
    "  classified = lines_classifier.LinesClassifier(\n",
    "      prepared_result, lines_classifier_constraints.LinesClassifierConstraints())\n",
    "  if DEBUG:\n",
    "    show(classified.get_debug_data())\n",
    "  for spec in classified.line_specs():\n",
    "    if DEBUG:\n",
    "      show('spec', spec._grid)\n",
    "    combined = prepared_result.fork().mask(spec._grid)\n",
    "    show('%s (%0.4f%%)' % (n, spec._score), combined.get_debug_data())\n",
    "    break  # Process just the first one.\n",
    "\n",
    "print('done')\n",
    "print(perf.report())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6749 157859 0.04275334317333823\n",
      "8140 157859 0.05156500421262012\n",
      "112196 160774 0.6978491547140707\n",
      "56510 159173 0.3550225226640196\n",
      "20523 157859 0.13000842524024606\n",
      "158473 163358 0.9700963527957003\n",
      "142070 162483 0.87436839546291\n",
      "131703 160623 0.8199510655385592\n",
      "100931 158557 0.6365597230018227\n",
      "18200 157908 0.11525698507991995\n",
      "38757 157908 0.24544038300782733\n",
      "45647 158058 0.28879904845056875\n",
      "55469 157908 0.3512741596372571\n",
      "69179 159628 0.43337635001378205\n",
      "99945 161393 0.6192647760435707\n",
      "83927 160016 0.524491300869913\n",
      "61947 135562 0.4569643410395243\n",
      "59462 106213 0.5598373080508036\n",
      "46059 152708 0.3016148466354088\n",
      "71975 136118 0.5287691561733202\n",
      "85447, 160415, 0.5326621575289094\n"
     ]
    }
   ],
   "source": [
    "print(6749, 157859, 0.04275334317333823)\n",
    "print(8140, 157859, 0.05156500421262012)\n",
    "print(112196, 160774, 0.6978491547140707)  # round()\n",
    "print(56510, 159173, 0.3550225226640196)  # round(1)\n",
    "print(20523, 157859, 0.13000842524024606)  # round(2)\n",
    "print(158473, 163358, 0.9700963527957003)  # 2, 5%\n",
    "print(142070, 162483, 0.87436839546291)  # 1, 1%\n",
    "print(131703, 160623, 0.8199510655385592)  # 1, 0.5%\n",
    "print(100931, 158557, 0.6365597230018227)  # 1, 0.1%\n",
    "print(18200, 157908, 0.11525698507991995)  # 1, 5/max\n",
    "print(38757, 157908, 0.24544038300782733)  # 2, 5/max\n",
    "print(45647, 158058, 0.28879904845056875)  # 2, 10/max\n",
    "print(55469, 157908, 0.3512741596372571)  # 2, 20/max\n",
    "print(69179, 159628, 0.43337635001378205)  # 2, 40/max\n",
    "print(99945, 161393, 0.6192647760435707)  # 2, 160/max <- bad results\n",
    "print(83927, 160016, 0.524491300869913)  # 2, 80/max <- OK\n",
    "print(61947, 135562, 0.4569643410395243)  # 2, 85/max <- OK\n",
    "print(59462, 106213, 0.5598373080508036)  # scale(2, 50/max) <- weak results\n",
    "print(46059, 152708, 0.3016148466354088)  # 100%, scale(1, 50/max) <- weak results\n",
    "print(71975, 136118, 0.5287691561733202)  # 95%, 1, 85/max\n",
    "print('%s, %s, %s' % (divide_distances_evenly.skip, divide_distances_evenly.total, divide_distances_evenly.skip / divide_distances_evenly.total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on (414x373)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48276fb002cf44edb798cfd87b811500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x9e\\x00\\x00\\x01u\\x08\\x00\\x00\\x00\\x00\\xfd\\x94\\xd3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ef465f2d40433bbd6291db58176852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x9e\\x00\\x00\\x01u\\x08\\x02\\x00\\x00\\x00W\\x9d\\x1b\\x1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on (420x364)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b7d6be7cd34ffd905f64fe8d360505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xa4\\x00\\x00\\x01l\\x08\\x00\\x00\\x00\\x00\\xa6\\x9c\\x92…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cb452d7e914bb7b2e3c285b66a57b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xa4\\x00\\x00\\x01l\\x08\\x02\\x00\\x00\\x00\\x0c\\x95Z\\xb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on (551x611)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c052998bf4cf4644916c39a45aee2af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\'\\x00\\x00\\x02c\\x08\\x00\\x00\\x00\\x00\\xf2\\xf2\\xee{\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821e9bb42a4f4ab588ab20404cf37b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\'\\x00\\x00\\x02c\\x08\\x02\\x00\\x00\\x00X\\xfb&\\xf0\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.image import contours_classifier, coloring, component, component_database, image, utils\n",
    "from puzzle.constraints.image import decompose_constraints\n",
    "\n",
    "importlib.reload(contours_classifier)\n",
    "importlib.reload(coloring)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(decompose_constraints)\n",
    "importlib.reload(decompose)\n",
    "importlib.reload(image)\n",
    "importlib.reload(image_problem)\n",
    "\n",
    "\n",
    "contours_classifier.show = show\n",
    "\n",
    "\n",
    "_FOCUS = {\n",
    "  'askew.png',\n",
    "   'arrow.png',\n",
    "#   'cages.png',\n",
    "#   'castlewall.png',\n",
    "#   'fillomino.png',\n",
    "#   'kenken.png',\n",
    "#   'nonogram.png',\n",
    "#  'pathfinder.png',\n",
    "   'thermo.png',\n",
    "#  'rowsgarden.png',\n",
    "#   'slitherlink.png',\n",
    "#  'spiral.png',\n",
    "#   'strimko.png',\n",
    "}\n",
    "\n",
    "\n",
    "for n, i in imgs():\n",
    "  p = image_problem.ImageProblem(n, i)\n",
    "  #show(p._decompose.get_debug_data())\n",
    "  src = p._prepare_image.get_result().get_debug_data()\n",
    "  height, width = src.shape[:2]\n",
    "  threshold = int(min(width, height) // 2)\n",
    "  #show('src', src)\n",
    "  # Edge detection\n",
    "  #canny = cv2.Canny(src, 50, 200, None, 3)\n",
    "  #kernel = np.ones((2, 2))\n",
    "  #cv2.dilate(canny, kernel, iterations = 1, dst=canny)\n",
    "  dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "  classified = contours_classifier.ContoursClassifier()\n",
    "  classified.classify(image.Image(src))\n",
    "  #show(classified._tmp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WIP source from grid.py:\n",
    "from data import lazy\n",
    "\n",
    "class Grid(object):\n",
    "  def grid_without_threshold(self) -> np.ndarray:\n",
    "    # TODO: Keep metadata on component positions.\n",
    "    grayscale = np.copy(self.grayscale_inv)\n",
    "    for mask, color in itertools.chain(\n",
    "        self._layer_masks(), self._component_masks(include_inverted=True)):\n",
    "      if color == 0:\n",
    "        weight = -1\n",
    "      else:\n",
    "        weight = 1\n",
    "      cv2.addWeighted(grayscale, 1, utils.antialias(mask), weight, 0, dst=grayscale)\n",
    "    return grayscale\n",
    "\n",
    "  @lazy.prop\n",
    "  def grid(self) -> np.ndarray:\n",
    "    src = np.array(np.where(self.grid_without_threshold > _THRESHOLD, _MAX, 0), dtype=np.uint8)\n",
    "    return utils.preserve_stroke(src, _MAX, .9)\n",
    "\n",
    "  def _layer_masks(self, n: int = 6, show = lambda *x: None) -> Iterable[Tuple[np.ndarray, int]]:\n",
    "    src = self.grayscale_inv\n",
    "    show(src)\n",
    "    # DO NOT SUBMIT: \"show\" param.\n",
    "    batches = list(reversed(list(\n",
    "        coloring.top_n_color_clusters(self._grayscale_inv_bincount, n))))\n",
    "    print(batches)\n",
    "    kernel_size = 5\n",
    "    kernel = utils.kernel_circle(kernel_size)\n",
    "    # Normalized kernal used during blurring. Multiply 2x to intensify.\n",
    "    kernel_normalized = 2 * kernel / np.count_nonzero(kernel)\n",
    "    forbidden_zone = np.zeros_like(src)\n",
    "    blocked_next = forbidden_zone\n",
    "    for batch in batches:\n",
    "      low, high = batch[0] - _THRESHOLD, batch[-1] + _THRESHOLD\n",
    "      targeted = np.where(((low < src) & (src < high)), src, 0)\n",
    "      blocked_count = np.count_nonzero((targeted != 0) & (blocked_next != 0))\n",
    "      print('blocked count:', blocked_count, 100 * blocked_count / src.size)\n",
    "      if low > 0 and high < _MAX:\n",
    "        print('targeted batch %s [%s, %s] (%s)' % (batch, low, high, kernel_size))\n",
    "        show(targeted)\n",
    "        show('brighter', np.where(src > high, 255, 0))\n",
    "        # WARNING: 1.75 is very finely tuned. Any lower and grid lines are\n",
    "        # removed.\n",
    "        opened = utils.preserve_stroke(targeted, low, 1.75)\n",
    "        if not np.any(opened):\n",
    "          continue\n",
    "        #opened_percent = 100 * np.count_nonzero(targeted) / opened.size\n",
    "        #if opened_percent < 1: continue\n",
    "        #print('opened %.02f' % opened_percent)\n",
    "        show('opened', opened)\n",
    "        yield opened, 0\n",
    "        if show:\n",
    "          blurred = cv2.filter2D(\n",
    "              opened,\n",
    "              cv2.CV_8UC1,\n",
    "              kernel_normalized,\n",
    "              borderType=cv2.BORDER_ISOLATED)\n",
    "          print('blurred')\n",
    "          show(blurred)\n",
    "          subtracted = src - blurred\n",
    "          result = np.array(np.where(src < blurred, 0, subtracted), dtype=np.uint8)\n",
    "          show('result', result)\n",
    "          show('nonzero', np.array(np.where(result > 0, 255, 0), dtype=np.uint8))\n",
    "      # Mark more territory as forbidden.\n",
    "      np.maximum(forbidden_zone, targeted, out=forbidden_zone)\n",
    "      blocked_next = cv2.dilate(forbidden_zone, kernel, iterations=2)\n",
    "      show('blocked_next', blocked_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = [\n",
    "  0, 5, 44, 47, 87, 90, 129, 134, 171, 175, 214, 222, 261, 264, 304, 307,\n",
    "  346, 350, 387, 392, 430, 438, 476, 481, 518, 521, 562, 564, 605, 608, 646,\n",
    "  654, 693, 697, 734, 739, 777, 781, 820, 824, 863, 870, 910, 912, 953, 955,\n",
    "  993, 998, 1036, 1038, 1079, 1086\n",
    "]\n",
    "distances = [i * 5 for i in range(20)]\n",
    "\n",
    "def convert(distances, window=1):\n",
    "  as_set = set(distances)\n",
    "  result = [int(i in as_set) for i in range(distances[-1] + 1)]\n",
    "  return np.convolve(result, np.array([1/window] * window))\n",
    "\n",
    "def plot_distances(*all_distances):\n",
    "  all_converted = []\n",
    "  for distances in all_distances:\n",
    "    as_axis = convert(distances)\n",
    "    all_converted.append(as_axis)\n",
    "    plt.plot(as_axis)\n",
    "    #print(' '.join(map(str, as_axis)))\n",
    "  plt.show()\n",
    "  all_fft = []\n",
    "  for as_axis in all_converted:\n",
    "    fft_result = np.abs(np.fft.fft(as_axis))\n",
    "    plt.plot(fft_result)\n",
    "    all_fft.append(fft_result)\n",
    "  plt.show()\n",
    "\n",
    "distances = sorted([i * 10 for i in range(20)] + [2 + i * 10 for i in range(20)])\n",
    "offset = []\n",
    "offset.extend([i * 10 + 9 for i in range(20)])\n",
    "doubled = [i * 20 for i in range(10)]\n",
    "#plot_distances(distances)\n",
    "#plot_distances(distances, offset, doubled)\n",
    "\n",
    "#plot_distances(original)\n",
    "\n",
    "# Observations:\n",
    "# len(fft) == len(input)\n",
    "# max(amplitude) = # sum of non-zero inputs\n",
    "# number of peaks (after x = 0) appears to equal number of zeros between numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape is (100, 100, 3)\n",
      "100x100 @ (50, 50) by 57 angle 29\n",
      "100x100 @ (50, 50) by -57 angle 29\n",
      "100x100 @ (50, 50) by 50 angle 90\n",
      "100x100 @ (50, 50) by -50 angle 90\n",
      "100x100 @ (50, 50) by -57 angle -30\n",
      "100x100 @ (50, 50) by -57 angle 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a841232eab04a0a99ba1e8617b3c670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00d\\x00\\x00\\x00d\\x08\\x02\\x00\\x00\\x00\\xff\\x80\\x02\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n850x989 @ (486, 425) by 29 = [-561, 420]\\n850x989 @ (486, 425) by 90 = [-425, 564]\\n850x989 @ (486, 425) by 149 = [-420, 561]\\n\\n\\nmoving (486, 425) by -561 at angle -29\\nmoving (486, 425) by 420 at angle -29\\nmoving (486, 425) by -561 at angle 29\\nmoving (486, 425) by 420 at angle 29\\nmoving (486, 425) by -425 at angle 90\\nmoving (486, 425) by 564 at angle 90\\n\\nmoving (100, 100) by -115 at angle -29\\nmoving (100, 100) by 200 at angle -29\\nmoving (100, 100) by -115 at angle 29\\nmoving (100, 100) by 866 at angle 29\\nmoving (100, 100) by -100 at angle 90\\nmoving (100, 100) by 889 at angle 90\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THETAS = (0, math.pi / 3, 2 * math.pi / 3)\n",
    "DEGREE = math.pi / 180\n",
    "width, height = 100, 100\n",
    "cx, cy = round(width // 2), round(height // 2)\n",
    "\n",
    "def distance(width, height, cx, cy, theta):\n",
    "  cos_theta = math.cos(theta)\n",
    "  if cos_theta > 0:  # Pointing right.\n",
    "    dx = width - cx\n",
    "  else:  # Pointing left.\n",
    "    dx = -cx\n",
    "  sin_theta = math.sin(theta)\n",
    "  if sin_theta > 0:  # Pointing up (down in image).\n",
    "    dy = height - cy\n",
    "  else:\n",
    "    dy = -cy\n",
    "  if cos_theta:\n",
    "    hypotenuse_to_x = dx / cos_theta\n",
    "  else:\n",
    "    hypotenuse_to_x = float('inf')\n",
    "  if sin_theta:\n",
    "    hypotenuse_to_y = dy / sin_theta\n",
    "  else:\n",
    "    hypotenuse_to_y = float('inf')\n",
    "  if theta > (2 * math.pi / 3):\n",
    "    print('%dx%d @ (%d, %d) by %d angle %d' % (\n",
    "      width, height, cx, cy, -min(hypotenuse_to_x, hypotenuse_to_y),\n",
    "      math.degrees(theta - math.pi)))\n",
    "  else:\n",
    "    print('%dx%d @ (%d, %d) by %d angle %d' % (\n",
    "      width, height, cx, cy, min(hypotenuse_to_x, hypotenuse_to_y),\n",
    "      math.degrees(theta)))\n",
    "  return min(hypotenuse_to_x, hypotenuse_to_y)\n",
    "\n",
    "\n",
    "img = np.zeros((height, width, 3))\n",
    "print('image shape is', img.shape)\n",
    "cv2.circle(img, (cx, cy), 2, (255, 255, 255), thickness=3)\n",
    "\n",
    "for color, base_theta in zip(coloring.colors(len(THETAS)), THETAS):\n",
    "  for offset in (0, math.pi):\n",
    "    theta = base_theta + offset + 30 * DEGREE\n",
    "    h = distance(width, height, cx, cy, theta)\n",
    "    dx = round(math.cos(theta) * h)\n",
    "    dy = round(math.sin(theta) * h)\n",
    "    cv2.line(img, (cx, cy), (cx + dx, cy + dy), color, thickness=1)\n",
    "    cv2.circle(img, (cx + dx, cy + dy), 4, (255, 255, 255), thickness=1)\n",
    "\n",
    "\n",
    "show(img)\n",
    "\n",
    "\"\"\"\n",
    "850x989 @ (486, 425) by 29 = [-561, 420]\n",
    "850x989 @ (486, 425) by 90 = [-425, 564]\n",
    "850x989 @ (486, 425) by 149 = [-420, 561]\n",
    "\n",
    "\n",
    "moving (486, 425) by -561 at angle -29\n",
    "moving (486, 425) by 420 at angle -29\n",
    "moving (486, 425) by -561 at angle 29\n",
    "moving (486, 425) by 420 at angle 29\n",
    "moving (486, 425) by -425 at angle 90\n",
    "moving (486, 425) by 564 at angle 90\n",
    "\n",
    "moving (100, 100) by -115 at angle -29\n",
    "moving (100, 100) by 200 at angle -29\n",
    "moving (100, 100) by -115 at angle 29\n",
    "moving (100, 100) by 866 at angle 29\n",
    "moving (100, 100) by -100 at angle 90\n",
    "moving (100, 100) by 889 at angle 90\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
